// LLM í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬
export interface LLMConfig {
  provider: 'openai' | 'claude' | 'gemini' | 'runware';
  model: string;
  apiKey: string;
  style?: string;
}

export interface LLMResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

export interface LLMMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

export interface LLMTool {
  name: string;
  description: string;
  parameters: any;
}

export interface LLMGenerateOptions {
  messages: LLMMessage[];
  tools?: LLMTool[];
  maxIterations?: number;
}

export abstract class BaseLLMClient {
  protected config: LLMConfig;

  constructor(config: LLMConfig) {
    this.config = config;
  }

  abstract generateText(messages: LLMMessage[], options?: { tools?: LLMTool[] }): Promise<LLMResponse>;
  abstract generateImage(prompt: string, options?: { quality?: 'low' | 'medium' | 'high'; size?: '512x768' | '768x512' | '1024x1024' | '1024x1536' | '1536x1024' | '1920x1080'; style?: 'photographic' | 'minimalist' | 'kawaii' | 'artistic' | 'impressionist' }): Promise<string>; // ì´ë¯¸ì§€ URL ë°˜í™˜
}

export class OpenAIClient extends BaseLLMClient {
  async generateText(messages: LLMMessage[], options?: { tools?: LLMTool[] }): Promise<LLMResponse> {
    const maxRetries = 2;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸ”µ OpenAI ${this.config.model} í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries})`);
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.config.apiKey}`
          },
          body: JSON.stringify({
            model: this.config.model,
            messages: messages.map(msg => ({
              role: msg.role,
              content: msg.content
            })),
            temperature: 0.7,
            max_tokens: 2000
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ OpenAI ì˜¤ë¥˜ ì‘ë‹µ (${attempt}/${maxRetries}):`, errorText);
          
          if (attempt === maxRetries) {
            throw new Error(`OpenAI API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
          }
          
          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();
        console.log(`âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ`);
        
        return {
          content: data.choices[0]?.message?.content || '',
          usage: {
            promptTokens: data.usage?.prompt_tokens || 0,
            completionTokens: data.usage?.completion_tokens || 0,
            totalTokens: data.usage?.total_tokens || 0
          }
        };
        
      } catch (error) {
        console.error(`OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);
        
        if (attempt === maxRetries) {
          throw error;
        }
        
        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }
    
    throw new Error('OpenAI í…ìŠ¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }

  async generateImage(prompt: string, options?: { quality?: 'low' | 'medium' | 'high'; size?: '512x768' | '768x512' | '1024x1024' | '1024x1536' | '1536x1024'; style?: 'photographic' | 'minimalist' | 'kawaii' | 'artistic' | 'impressionist' }): Promise<string> {
    const maxRetries = 2;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸ”µ OpenAI ${this.config.model} ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries})`);

        // ëª¨ë¸ë³„ ì§€ì› í•´ìƒë„ ë§¤í•‘
        let requestSize: string;

        if (this.config.model === 'gpt-image-1') {
          // gpt-image-1ì€ íŠ¹ì • í¬ê¸°ë§Œ ì§€ì›
          const gptImageSizeMapping: {[key: string]: string} = {
            '1024x1024': '1024x1024',
            '1024x1536': '1024x1536',
            '1536x1024': '1536x1024',
            '512x768': '1024x1024', // ì§€ì› í¬ê¸°ë¡œ ë§¤í•‘
            '768x512': '1024x1024'
          };
          requestSize = gptImageSizeMapping[options?.size || '1024x1024'] || '1024x1024';
        } else {
          // DALL-E 3 ëª¨ë¸
          const dalle3SizeMapping: {[key: string]: string} = {
            '1024x1024': '1024x1024',
            '1024x1536': '1024x1792',
            '1536x1024': '1792x1024',
            '512x768': '1024x1024',
            '768x512': '1024x1024'
          };
          requestSize = dalle3SizeMapping[options?.size || '1024x1024'] || '1024x1024';
        }

        const requestBody: any = {
          model: this.config.model,
          prompt: prompt,
          size: requestSize,
          n: 1
        };

        if (this.config.model === 'gpt-image-1') {
          // gpt-image-1 íŒŒë¼ë¯¸í„° ì„¤ì •
          const qualityMapping = {
            'low': 'low',
            'medium': 'medium',
            'high': 'high'
          };
          requestBody.quality = qualityMapping[options?.quality as keyof typeof qualityMapping] || 'high';
          requestBody.response_format = 'url'; // gpt-image-1ì€ URL ë°˜í™˜
        } else if (this.config.model === 'dall-e-3') {
          // DALL-E 3 íŒŒë¼ë¯¸í„° ì„¤ì •
          requestBody.quality = options?.quality === 'low' ? 'standard' : 'hd';
          requestBody.style = 'vivid';
          requestBody.response_format = 'url';
        }

        const response = await fetch('https://api.openai.com/v1/images/generations', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.config.apiKey}`
          },
          body: JSON.stringify(requestBody)
        });

        console.log(`ğŸ“Š OpenAI ì‘ë‹µ ìƒíƒœ: ${response.status}`);

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ OpenAI ì˜¤ë¥˜ ì‘ë‹µ (${attempt}/${maxRetries}):`, errorText);
          
          if (attempt === maxRetries) {
            throw new Error(`OpenAI Image API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
          }
          
          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();
        console.log(`âœ… OpenAI ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ`);

        if (this.config.model === 'gpt-image-1' || this.config.model === 'dall-e-3') {
          // gpt-image-1ê³¼ DALL-E 3ëŠ” URL í˜•íƒœë¡œ ë°˜í™˜
          const imageUrl = data.data?.[0]?.url;
          if (imageUrl) {
            return imageUrl;
          }
        }

        console.error('OpenAI ì‘ë‹µ êµ¬ì¡°:', JSON.stringify(data, null, 2));

        if (attempt === maxRetries) {
          throw new Error('OpenAIì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.');
        }

        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
        continue;
        
      } catch (error) {
        console.error(`OpenAI Image API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);
        
        if (attempt === maxRetries) {
          throw error;
        }
        
        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }
    
    throw new Error('OpenAI ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}

export class ClaudeClient extends BaseLLMClient {
  async generateText(messages: LLMMessage[], options?: { tools?: LLMTool[] }): Promise<LLMResponse> {
    const maxRetries = 2;
    
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸŸ£ Claude ${this.config.model} í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries})`);
        
        const response = await fetch('https://api.anthropic.com/v1/messages', {
          method: 'POST',
          headers: {
            'x-api-key': this.config.apiKey,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            model: this.config.model,
            max_tokens: 2000,
            messages: messages.map(msg => ({
              role: msg.role === 'system' ? 'user' : msg.role,
              content: msg.role === 'system' ? `System: ${msg.content}` : msg.content
            }))
          })
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ Claude ì˜¤ë¥˜ ì‘ë‹µ (${attempt}/${maxRetries}):`, errorText);
          
          if (attempt === maxRetries) {
            throw new Error(`Claude API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
          }
          
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();
        console.log(`âœ… Claude ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ`);
        
        return {
          content: data.content[0]?.text || '',
          usage: {
            promptTokens: data.usage?.input_tokens || 0,
            completionTokens: data.usage?.output_tokens || 0,
            totalTokens: (data.usage?.input_tokens || 0) + (data.usage?.output_tokens || 0)
          }
        };
        
      } catch (error) {
        console.error(`Claude API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);
        
        if (attempt === maxRetries) {
          throw error;
        }
        
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }
    
    throw new Error('Claude í…ìŠ¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }

  async generateImage(prompt: string, options?: { quality?: 'low' | 'medium' | 'high'; size?: '512x768' | '768x512' | '1024x1024' | '1024x1536' | '1536x1024'; style?: 'photographic' | 'minimalist' | 'kawaii' | 'artistic' | 'impressionist' }): Promise<string> {
    throw new Error('ClaudeëŠ” ì´ë¯¸ì§€ ìƒì„±ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
  }
}

export class GeminiClient extends BaseLLMClient {
  async generateText(messages: LLMMessage[], options?: { tools?: LLMTool[] }): Promise<LLMResponse> {
    const maxRetries = 2;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸŸ¡ Gemini ${this.config.model} í…ìŠ¤íŠ¸ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries})`);

        // ë©”ì‹œì§€ë¥¼ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        let textContent = '';
        for (const message of messages) {
          if (message.role === 'system') {
            textContent += `System: ${message.content}\n\n`;
          } else if (message.role === 'user') {
            textContent += `User: ${message.content}`;
          }
        }

        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/${this.config.model}:generateContent?key=${this.config.apiKey}`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              contents: [{
                parts: [{
                  text: textContent
                }]
              }],
              generationConfig: {
                maxOutputTokens: 2000,
                temperature: 0.7
              }
            })
          }
        );

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ Gemini ì˜¤ë¥˜ ì‘ë‹µ (${attempt}/${maxRetries}):`, errorText);

          if (attempt === maxRetries) {
            throw new Error(`Gemini API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
          }

          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();
        console.log(`âœ… Gemini ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ`);

        return {
          content: data.candidates[0]?.content?.parts[0]?.text || '',
          usage: {
            promptTokens: data.usageMetadata?.promptTokenCount || 0,
            completionTokens: data.usageMetadata?.candidatesTokenCount || 0,
            totalTokens: data.usageMetadata?.totalTokenCount || 0
          }
        };

      } catch (error) {
        console.error(`Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);

        if (attempt === maxRetries) {
          throw error;
        }

        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }

    throw new Error('Gemini í…ìŠ¤íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }

  async generateImage(prompt: string, options?: { quality?: 'low' | 'medium' | 'high'; size?: '512x768' | '768x512' | '1024x1024' | '1024x1536' | '1536x1024' | '1920x1080'; style?: 'photographic' | 'minimalist' | 'kawaii' | 'artistic' | 'impressionist' }): Promise<string> {
    const maxRetries = 2;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸŸ¡ Gemini 2.5 Flash Image ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries})`);

        // GeminiëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì •ì‚¬ê°í˜•ë§Œ ìƒì„±í•˜ë¯€ë¡œ í¬ê¸° ì˜µì…˜ ë¬´ì‹œ
        let enhancedPrompt = prompt;

        // ìŠ¤íƒ€ì¼ ì˜µì…˜ ì²˜ë¦¬ (Gemini ìµœì í™”)
        const style = options?.style || 'photographic';
        if (style === 'photographic') {
          enhancedPrompt += ', studio-lit photography, high-resolution commercial photography, professional quality';
        } else if (style === 'minimalist') {
          enhancedPrompt += ', minimalist design, clean composition, negative space';
        } else if (style === 'kawaii') {
          enhancedPrompt += ', kawaii style, cute and colorful, soft pastel colors';
        } else if (style === 'artistic') {
          enhancedPrompt += ', artistic illustration, detailed brushwork, creative composition';
        } else if (style === 'impressionist') {
          enhancedPrompt += ', impressionist style, Van Gogh inspired, painterly brushstrokes';
        }

        console.log(`ğŸ¨ ìŠ¤íƒ€ì¼: ${style}, í–¥ìƒëœ í”„ë¡¬í”„íŠ¸: "${enhancedPrompt}"`);

        // Gemini 2.5 Flash Image Preview ëª¨ë¸ ì‚¬ìš© (2025ë…„ 8ì›” ì¶œì‹œ)
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-image-preview:generateContent?key=${this.config.apiKey}`,
          {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              contents: [{
                parts: [{
                  text: enhancedPrompt // ë¹„ìœ¨ ì •ë³´ê°€ ì¶”ê°€ëœ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                }]
              }]
            })
          }
        );

        console.log(`ğŸ“Š Gemini ì‘ë‹µ ìƒíƒœ: ${response.status}`);

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ Gemini ì˜¤ë¥˜ ì‘ë‹µ (${attempt}/${maxRetries}):`, errorText);

          if (attempt === maxRetries) {
            throw new Error(`Gemini Image API ì˜¤ë¥˜: ${response.status} ${response.statusText}`);
          }

          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();
        console.log(`âœ… Gemini ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ`);

        // Gemini 2.5 Flash Imageì˜ ì‹¤ì œ ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¥¸ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
        const parts = data.candidates?.[0]?.content?.parts;
        let imageData = null;

        if (parts && Array.isArray(parts)) {
          // parts ë°°ì—´ì—ì„œ inlineDataê°€ ìˆëŠ” ìš”ì†Œ ì°¾ê¸°
          for (const part of parts) {
            if (part.inlineData && part.inlineData.data) {
              imageData = part.inlineData.data;
              break;
            }
          }
        }

        if (imageData) {
          console.log('âœ… Gemini ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ');
          // Base64 ë°ì´í„°ë¥¼ data URLë¡œ ë³€í™˜
          return `data:image/png;base64,${imageData}`;
        } else {
          console.error('Gemini ì‘ë‹µ êµ¬ì¡°:', JSON.stringify(data, null, 2));

          if (attempt === maxRetries) {
            throw new Error('Geminiì—ì„œ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
          }

          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

      } catch (error) {
        console.error(`Gemini Image API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);

        if (attempt === maxRetries) {
          throw error;
        }

        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }

    throw new Error('Gemini ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}

// Runware ìŠ¤íƒ€ì¼ë³„ ì‹¤ì œ ëª¨ë¸ ë§¤í•‘
const runwareStyleModels = {
  'sdxl-base': {
    realistic: 'civitai:4201@130072', // Realistic Vision V6.0
    photographic: 'civitai:102438@133677', // SDXL Base (ì‚¬ì§„ íŠ¹í™”)
    illustration: 'civitai:24149@144666', // Mistoon Anime (ì¼ëŸ¬ìŠ¤íŠ¸)
    anime: 'civitai:24149@144666', // Mistoon Anime
    dreamy: 'civitai:1125067@1250712' // CyberRealistic (ëª½í™˜ì )
  },
  'flux-base': {
    realistic: 'civitai:618692@691639', // FLUX.1 Schnell
    photographic: 'civitai:618692@691639', // FLUX.1 Schnell
    illustration: 'civitai:618692@691639', // FLUX.1 Schnell
    anime: 'civitai:618692@691639', // FLUX.1 Schnell
    dreamy: 'civitai:618692@691639' // FLUX.1 Schnell
  }
};

export class RunwareClient extends BaseLLMClient {
  async generateText(messages: LLMMessage[], options?: { tools?: LLMTool[] }): Promise<LLMResponse> {
    throw new Error('RunwareëŠ” í…ìŠ¤íŠ¸ ìƒì„±ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ìƒì„± ì „ìš©ì…ë‹ˆë‹¤.');
  }

  async generateImage(prompt: string, options?: { quality?: 'low' | 'medium' | 'high'; size?: '512x768' | '768x512' | '1024x1024' | '1024x1536' | '1536x1024'; style?: 'photographic' | 'minimalist' | 'kawaii' | 'artistic' | 'impressionist' }): Promise<string> {
    const maxRetries = 2;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        console.log(`ğŸš€ Runware ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ (${attempt}/${maxRetries}) - í”„ë¡¬í”„íŠ¸: ${prompt}`);

        // í•´ìƒë„ ì˜µì…˜ì„ width, heightë¡œ ë³€í™˜
        let width = 1024;
        let height = 1024;

        if (options?.size) {
          const [w, h] = options.size.split('x').map(Number);
          width = w;
          height = h;
        }

        // í’ˆì§ˆì— ë”°ë¥¸ steps ì„¤ì • (RunwareëŠ” stepsë¡œ í’ˆì§ˆ ì¡°ì ˆ)
        let steps = 20; // ê¸°ë³¸ê°’
        if (options?.quality === 'low') steps = 10;
        else if (options?.quality === 'medium') steps = 15;
        else if (options?.quality === 'high') steps = 25;

        // ìŠ¤íƒ€ì¼ì— ë”°ë¥¸ ì‹¤ì œ ëª¨ë¸ ì„ íƒ (v2ì™€ ë™ì¼í•˜ê²Œ configì—ì„œ ê°€ì ¸ì˜´)
        let actualModel = this.config.model;
        console.log(`ğŸ” Runware ì„¤ì • í™•ì¸:`, {
          configModel: this.config.model,
          configStyle: this.config.style,
          optionsStyle: options?.style,
          availableStyleModels: Object.keys(runwareStyleModels)
        });

        // options ìŠ¤íƒ€ì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ config ìŠ¤íƒ€ì¼ ì‚¬ìš© (v2ì™€ ë™ì¼)
        const styleToUse = options?.style || this.config.style;

        if (styleToUse && runwareStyleModels[this.config.model as keyof typeof runwareStyleModels]) {
          const styleModels = runwareStyleModels[this.config.model as keyof typeof runwareStyleModels];
          actualModel = styleModels[styleToUse as keyof typeof styleModels] || this.config.model;
          console.log(`ğŸ¨ Runware ìŠ¤íƒ€ì¼ ë§¤í•‘: ${this.config.model} + ${styleToUse} â†’ ${actualModel}`);
        } else {
          console.log(`âš ï¸ ìŠ¤íƒ€ì¼ ë§¤í•‘ ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©: ${actualModel}`);
        }

        // UUID ìƒì„± (ê°„ë‹¨í•œ ë°©ë²•)
        const taskUUID = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
          const r = Math.random() * 16 | 0;
          const v = c === 'x' ? r : (r & 0x3 | 0x8);
          return v.toString(16);
        });

        const response = await fetch('https://api.runware.ai/v1', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${this.config.apiKey}`
          },
          body: JSON.stringify([
            {
              taskType: 'imageInference',
              taskUUID: taskUUID,
              positivePrompt: prompt,
              width: width,
              height: height,
              model: actualModel, // ìŠ¤íƒ€ì¼ì— ë”°ë¼ ë§¤í•‘ëœ ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©
              numberResults: 1,
              steps: steps,
              CFGScale: 7,
              seed: Math.floor(Math.random() * 1000000)
            }
          ])
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error(`âŒ Runware API ìƒì„¸ ì˜¤ë¥˜ (${attempt}/${maxRetries}):`, errorText);
          console.error(`ğŸ“ ìš”ì²­ ë°ì´í„°:`, JSON.stringify({
            taskType: 'imageInference',
            taskUUID: taskUUID,
            positivePrompt: prompt,
            width: width,
            height: height,
            model: actualModel,
            numberResults: 1,
            steps: steps,
            CFGScale: 7,
            seed: Math.floor(Math.random() * 1000000)
          }, null, 2));

          if (attempt === maxRetries) {
            throw new Error(`Runware API ì˜¤ë¥˜: ${response.status} ${response.statusText} - ${errorText}`);
          }

          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

        const data = await response.json();

        // ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
        if (data.data && data.data[0] && data.data[0].imageURL) {
          console.log(`âœ… Runware ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: ${data.data[0].imageURL}`);
          return data.data[0].imageURL;
        } else {
          console.error('Runware ì‘ë‹µ êµ¬ì¡°:', JSON.stringify(data, null, 2));

          if (attempt === maxRetries) {
            throw new Error('Runwareì—ì„œ ì´ë¯¸ì§€ URLì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
          }

          // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
          await new Promise(resolve => setTimeout(resolve, 500 * attempt));
          continue;
        }

      } catch (error) {
        console.error(`Runware API í˜¸ì¶œ ì‹¤íŒ¨ (${attempt}/${maxRetries}):`, error);

        if (attempt === maxRetries) {
          throw error;
        }

        // ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸° (500ms * attempt)
        await new Promise(resolve => setTimeout(resolve, 500 * attempt));
      }
    }

    throw new Error('Runware ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.');
  }
}

export class LLMClientFactory {
  private static writingClient: BaseLLMClient | null = null;
  private static imageClient: BaseLLMClient | null = null;

  static createClient(config: LLMConfig): BaseLLMClient {
    switch (config.provider) {
      case 'openai':
        return new OpenAIClient(config);
      case 'claude':
        return new ClaudeClient(config);
      case 'gemini':
        return new GeminiClient(config);
      case 'runware':
        return new RunwareClient(config);
      default:
        throw new Error(`ì§€ì›ë˜ì§€ ì•ŠëŠ” LLM ê³µê¸‰ì—…ì²´: ${config.provider}`);
    }
  }

  static setWritingClient(config: LLMConfig): void {
    this.writingClient = this.createClient(config);
  }

  static setImageClient(config: LLMConfig): void {
    this.imageClient = this.createClient(config);
  }

  static getWritingClient(): BaseLLMClient {
    if (!this.writingClient) {
      throw new Error('Writing LLM client not configured');
    }
    return this.writingClient;
  }

  static getImageClient(): BaseLLMClient {
    if (!this.imageClient) {
      throw new Error('Image LLM client not configured');
    }
    return this.imageClient;
  }

  static hasWritingClient(): boolean {
    return this.writingClient !== null;
  }

  static hasImageClient(): boolean {
    return this.imageClient !== null;
  }
}